# -*- coding: utf-8 -*-
"""3-1.(강의)img_CNN(IDG)모델.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T4YhHpaMDJndIX2irPymHGHH-cArvmQ5

# 3. 이미지 분류 모델 
+ 총 4문제 출제. 타입을 둘로 나눠볼 수 있음. 각 2문제
+ A type: Image Data Generator 활용한 이미지 분류 문제
+ B type: tfds 활용한 이미지 분류 문제

### Image Data Generator 개요
+ 인간과 다르게 컴퓨터 딥러닝은 이미지 속 인물이 같은 사람일지라도 상하,좌우 반전 혹은 축 이동이 있으면 같다고 인지하지 못한다. 
+ 이러한 문제점을 Image Augmentation(변형) 기법을 통해서 해결 할 수 있다.
    + ImageDataGenerator()
"""

training_datagen = ImageDataGenerator(
    rescale = 1. / 255,       # 이미지 픽셀 값 조정
    rotation_range = 40,      # 이미지 회전, 0~40도의 범위에서 랜덤하게 회전
    width_shift_range = 0.2,  # 가로 방향으로 이동, 단위: %, 0 ~ 20% 범위에서 랜덤하게 이동
    height_shift_range=0.2,   # 세로 방향으로 이동, 안위: %, 0 ~ 20% 범위에서 랜덤하게 이동
    shear_range=0.2,          # 이미지 굴절
    zoom_range = 0.2,         # 이미지 확대
    horizontal_flip = True,   # 수평 방향으로 이미지 반전 (좌우반전)
    fill_mode = 'nearest',    # 이미지 변형 시 비게되는 픽셀값 채운다.  'reflect'도 있음
    validation_split=0.2,     # 데이터셋이 1개일 경우 80%를 테스트 데이터로, 20%를 검증 데이터로 쓴다. 
)

"""### 로컬 컴퓨터에 이미지 폴더 생성할 때
+ root 폴더 (최상단) 만들기
+ A / B / C ... 클래스별로 분류해서 하위 폴더 만들고 이미지 분류
+ IDG 경로를 root로만 잡아주면 IDG 함수가 root 안에 있는 폴더 갯수를 곧 클래스 갯수로 인식
+ 각 폴더 안에 있는 이미지를 분석해서 라벨링까지 해준다.
"""

training_generator = training_datagen.flow_from_directory(TRAINING_DIR,     # flow_from_directory : 로컬컴퓨터에서 이미지를 ()안의 옵션값 대로 불러온다. 
                                                          batch_size=32,
                                                          target_size=(150,150), # 사이즈 일괄 지정해주는데 문제에서 주어진다. 
                                                          class_mode='categorical',  # 출력층이 'softmax'면 'categorical', 'sigmoid'면 'binary'
                                                          subset='training')   # 앞에서 validation_split = 0.2로 지정해 주었을 때만 subset을 반드시 training으로 정해줘야 80%의 학습데이터를 학습시킨다.

validation_generator = training_datagen.flow_from_directory(TRAINING_DIR,
                                                            batch_size=32,
                                                            targer_size=(150,150),
                                                            class_mode = 'categorical',
                                                            subset = 'validation')

"""### Convolutaion Neural Network (합성곱 신경망) CNN 
+ 모델링 구성할 때 특성추출(feature extraction) 먼저, 연산 덴스(classification) 나중에

풍경  =  원본이미지

카메라 = CNN 필터

사진 = feature map

---
#### 작동 원리 
+ 필터가 원본이미지를 돌아다니면서 같은 자리에 있는 값을 각각 곱해서 더한다. 
+ 더한 값을 feature map에 저장한다.
+ 필터 크기가 3*3일 경우 feature map은 원본에 비해 가로2, 세로 2 씩 사이즈가 줄어든다.
+ 픽셀이 줄어드는게 싫을 경우 원본 주변에 0 패딩 넣으면 됨. 문제마다 다르게 만들면됨 (padding = 'same')
+ 필터 갯수 지정: 하나의 원본이미지에 대해서 서로 다른 30장의 이미지를 추출해내고 싶으면 필터 갯수를 30개로 지정한다. (필터들의 인자 값은 랜덤하기때문에 다 다르다. 결과물도 달라짐)
"""

# 코드
Conv2D(64,(3,3), activation = 'relu')   # 64: 필터갯수(8*8) , (3,3):필터사이즈

"""### MaxPooling2D
+ 이미지 사이즈가 줄어들면 연산량도 줄어든다. 
+ pooling layer로 이미지 크기 줄인다. 
+ ex) MaxPooling(2,2) : output 이미지 사이즈가 1/2 * 1/2  = 1/4 로 줄어든다.
"""

# 샘플 모델링

model = Sequential([
    # 특징 추출 (feature extractor)
    Conv2D((3,3), activation = 'relu', input_shape = (150,150,3)),  # 필터사이즈: 3*3 ,  # input_shape: 150*150 이미지 3장 (컬러사진은 컬러 채널이 R,G,B 3개 있음. )
    MaxPooling2D(2,2),
    Conv2D(64,(3,3), activation = 'relu'),
    MaxPooling2D(2,2),64,
    Conv2D(128,(3,3), activation = 'relu'),
    MaxPooling2D(2,2),
    Conv2D(128,(3,3), activation = 'relu' ),  # 필터 갯수는 늘려주면 좋고, 이미지  복잡도에 따라서 덴스를 깊게 해줘도 된다. 
    MaxPooling2D(2,2),

    # Classifier 
    Flatten(),  # 2D를 1D로 변환
    Dropout(0.5),   # 노드 50%만 추출해서 학습: 과대적합 방지. 학습에만 사용되고, 예측에서는 사용안됨 
    Dense(512,activation = 'relu'),
    Dense(3, activation = 'softmax')
])